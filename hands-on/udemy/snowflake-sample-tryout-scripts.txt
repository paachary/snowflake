use role accountadmin;

CREATE ROLE Data_Science;

GRANT USAGE ON WAREHOUSE compute_wh to data_science;
GRANT USAGE ON WAREHOUSE compute_wh to developer;
GRANT MONITOR on warehouse COMPUTE_WH to role DEVELOPER;
GRANT MONITOR on warehouse COMPUTE_WH to role data_science;

CREATE USER ds_1 PASSWORD = '****' LOGIN_NAME = ds_1 DEFAULT_ROLE = data_science
DEFAULT_WAREHOUSE = 'compute_wh' MUST_CHANGE_PASSWORD = false;

CREATE USER dev_1 PASSWORD = '****' LOGIN_NAME = dev_1 DEFAULT_ROLE = developer
DEFAULT_WAREHOUSE = 'compute_wh' MUST_CHANGE_PASSWORD = false;

GRANT ROLE data_science to USER ds_1;
GRANT ROLE developer to USER dev_1;
GRANT USAGE ON schema PUBLIC to role developer;

CREATE OR REPLACE FILE FORMAT pipe_file_format
COMPRESSION = 'AUTO' 
FIELD_DELIMITER = '|' 
RECORD_DELIMITER = '\n' 
SKIP_HEADER = 1 
FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' 
TRIM_SPACE = FALSE 
ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE 
ESCAPE = 'NONE' 
ESCAPE_UNENCLOSED_FIELD = '\134' 
DATE_FORMAT = 'AUTO' 
TIMESTAMP_FORMAT = 'AUTO' 
NULL_IF = ('\\N');

CREATE OR REPLACE STAGE stage_internal FILE_FORMAT= (FORMAT_NAME=pipe_file_format);

put file://./dataFeb-5-2020.csv @stage_internal;

ls @stage_internal;

CREATE or replace TABLE 
customer (
            customer_id STRING,
            customer_name STRING,
            customer_email STRING,
            customer_city STRING,
            customer_dob DATE
);

GRANT SELECT ON customer TO ROLE public;

COPY INTO customer (customer_id,
                customer_name,
                customer_email,
                customer_city,
                customer_dob)
FROM ( SELECT t.$1, t.$2, t.$3, t.$4, to_Date(t.$5) FROM @stage_internal t);

SELECT * FROM customer;

GRANT SELECT ON customer TO ROLE data_science;
GRANT SELECT ON customer TO ROLE DEVELOPER;

-------------------------------------------------------------
CLUSTERING

CREATE OR REPLACE WAREHOUSE performance_test warehouse_size = LARGE;

use performance_test;

CREATE OR REPLACE TABLE transactions 
(transaction_dt DATE, transaction_id INTEGER, customer_id INTEGER, amount INTEGER);

CREATE OR REPLACE STAGE s3_perf_stage URL = 's3://snowflake-essentials/streaming_data_ingest/Transactions';

COPY INTO transactions FROM @s3_perf_stage file_format = (type=csv field_delimiter='|' skip_header=1);

CREATE OR REPLACE table transactions_large (transaction_dt, transaction_id, customer_id, amount )
as select a.transaction_dt + mod(random(), 2000), random(), a.customer_id, a.amount
from transactions a cross join transactions b cross join transactions c cross join transactions d;

select count(*) from transactions_large where transaction_dt = date '2018-12-18';

CREATE OR REPLACE table transactions_clustered_large (transaction_dt, transaction_id, customer_id, amount )
cluster by (transaction_dt)
as select a.transaction_dt + mod(random(), 2000), random(), a.customer_id, a.amount
from transactions a cross join transactions b cross join transactions c cross join transactions d;

select count(*) from transactions_clustered_large where transaction_dt = date '2018-12-18';

select count(*) from transactions_large where transaction_dt between date '2018-12-01' and date '2018-12-31';

select count(*) from transactions_clustered_large where transaction_dt between date '2018-12-01' and date '2018-12-31';

CREATE OR REPLACE table transactions_clustered_xprs (transaction_dt DATE, transaction_id INT, customer_id INT, amount INT)
cluster by ( date_trunc('MONTH', transaction_dt))
as select transaction_dt, transaction_id, customer_id, amount
from transactions_clustered_large;

select count(*) from transactions_clustered_xprs where date_trunc('MONTH', transaction_dt) = date '2018-12-01';

select count(*) from transactions_large where date_trunc('MONTH', transaction_dt) = date '2018-12-01';

select count(*) from transactions_clustered_large where date_trunc('MONTH', transaction_dt) = date '2018-12-01';
 


