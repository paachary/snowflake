use role accountadmin;

CREATE ROLE Data_Science;
CREATE ROLE developer;

GRANT USAGE ON WAREHOUSE compute_wh to data_science;
GRANT USAGE ON WAREHOUSE compute_wh to developer;
GRANT MONITOR on warehouse COMPUTE_WH to role DEVELOPER;
GRANT MONITOR on warehouse COMPUTE_WH to role data_science;

CREATE USER ds_1 PASSWORD = '****' LOGIN_NAME = ds_1 DEFAULT_ROLE = data_science
DEFAULT_WAREHOUSE = 'compute_wh' MUST_CHANGE_PASSWORD = false;

CREATE USER dev_1 PASSWORD = '****' LOGIN_NAME = dev_1 DEFAULT_ROLE = developer
DEFAULT_WAREHOUSE = 'compute_wh' MUST_CHANGE_PASSWORD = false;

GRANT ROLE data_science to USER ds_1;
GRANT ROLE developer to USER dev_1;
GRANT USAGE ON schema PUBLIC to role developer;

----------------------------------------------------------------------------------

---** Loading data from stage **

CREATE OR REPLACE DATABASE integration_db;

USE DATABASE integration_db;

CREATE OR REPLACE SCHEMA int;

CREATE TABLE json_raw ( col variant);

-- User Stage
-- Referenced by @~
-- convenient option if your files will only be accessed by a single user, but need to be copied into multiple tables.
-- Unlike named stages, user stages cannot be altered or dropped.
-- user stages do not support setting file format options. Instead, you must specify file format and copy options as part of the COPY INTO <table> command.

-- example:

put file://./contacts.json @~;

list @~;

copy into JSON_RAW from @~/contacts.json file_format=(type=json) PURGE = TRUE;

-- this option is not appropriate if:

-- Multiple users require access to the files.

-- The current user does not have INSERT privileges on the tables the data will be loaded into.

--------------------------------------

--- Table Stage
-- Referenced by @%<table_name>

-- Each table has a Snowflake stage allocated to it by default for storing files. 

-- This stage is a convenient option if your files need to be accessible to multiple users and only need to be copied into a single table.

-- Table stages have the same name as the table; e.g. a table named mytable has a stage referenced as @%mytable.

-- Unlike named stages, table stages cannot be altered or dropped.

-- Table stages do not support setting file format options. Instead, you must specify file format and copy options as part of the COPY INTO <table> command.

-- Table stage is not a separate database object; rather, it is an implicit stage tied to the table itself. 

-- example:

put file://./contacts.json @%json_raw;

list @%json_raw;

copy into JSON_RAW from @%json_raw/contacts.json file_format=(type=json) PURGE = TRUE;

-- Table stages do not support transforming data while loading it (i.e. using a query as the source for the COPY command).
    
    -- example of above error

    SELECT * FROM @%JSON_RAW;
    
     --   100080 (22000): Number of columns in file (4) does not match that of the corresponding table (1), use file format option error_on_column_count_mismatch=false to ignore this error
     --     File '@JSON_RAW/contacts.json.gz', line 2, character 1
     --     Row 1 starts at line 1, column "JSON_RAW"[4]

-------------------------------------------------------------

-- Named internal Stage
-- Referenced by @<name>

-- Internal stages are named database objects that provide the greatest degree of flexibility for data loading. 

-- Named internal stages are optional but recommended when you plan regular data loads that could involve multiple users and/or tables.

-- Users with the appropriate privileges on the stage can load data into any table.

-- Ownership of the stage can be transferred to another role, and privileges granted to use the stage can be modified to add or remove roles.

-- When you create a stage, you must explicitly grant privileges on the stage to one or more roles before users with those roles can use the stage.


CREATE OR REPLACE FILE FORMAT pipe_file_format
    COMPRESSION = 'AUTO' 
    FIELD_DELIMITER = '|' 
    RECORD_DELIMITER = '\n' 
    SKIP_HEADER = 1 
    FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' 
    TRIM_SPACE = FALSE 
    ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE 
    ESCAPE = 'NONE' 
    ESCAPE_UNENCLOSED_FIELD = '\134' 
    DATE_FORMAT = 'AUTO' 
    TIMESTAMP_FORMAT = 'AUTO' 
    NULL_IF = ('\\N');

CREATE OR REPLACE STAGE stage_internal FILE_FORMAT= (FORMAT_NAME=pipe_file_format);

put file://./dataFeb-5-2020.csv @stage_internal;

ls @stage_internal;

CREATE or replace TABLE 
customer (
            customer_id STRING,
            customer_name STRING,
            customer_email STRING,
            customer_city STRING,
            customer_dob DATE
);

GRANT SELECT ON customer TO ROLE public;

COPY INTO customer (customer_id,
                customer_name,
                customer_email,
                customer_city,
                customer_dob)
FROM ( SELECT t.$1, t.$2, t.$3, t.$4, to_Date(t.$5) FROM @stage_internal t);

SELECT * FROM customer;

GRANT SELECT ON customer TO ROLE data_science;
GRANT SELECT ON customer TO ROLE DEVELOPER;

-------------------------------------------------------------------------

CLUSTERING

CREATE OR REPLACE WAREHOUSE performance_test warehouse_size = LARGE;

CREATE OR REPLACE DATABASE performance_db;

CREATE OR REPLACE SCHEMA perf;

use warehouse performance_test;

USE database performance_db;

USE schema perf;

CREATE OR REPLACE TABLE transactions 
(transaction_dt DATE, transaction_id INTEGER, customer_id INTEGER, amount INTEGER);

CREATE OR REPLACE STAGE s3_perf_stage URL = 's3://snowflake-essentials/streaming_data_ingest/Transactions';

COPY INTO transactions FROM @s3_perf_stage file_format = (type=csv field_delimiter='|' skip_header=1);

CREATE OR REPLACE table transactions_large (transaction_dt, transaction_id, customer_id, amount )
as select a.transaction_dt + mod(random(), 2000), random(), a.customer_id, a.amount
from transactions a cross join transactions b cross join transactions c cross join transactions d;

select count(*) from transactions_large where transaction_dt = date '2018-12-18';

select count(*) from transactions_large where transaction_dt = date '2020-03-03';

CREATE OR REPLACE table transactions_clustered_large (transaction_dt, transaction_id, customer_id, amount )
cluster by (transaction_dt)
as select a.transaction_dt + mod(random(), 2000), random(), a.customer_id, a.amount
from transactions a cross join transactions b cross join transactions c cross join transactions d;

select count(*) from transactions_clustered_large where transaction_dt = date '2018-12-18';

select count(*) from transactions_large where transaction_dt between date '2018-12-01' and date '2018-12-31';

select count(*) from transactions_clustered_large where transaction_dt between date '2018-12-01' and date '2018-12-31';

CREATE OR REPLACE table transactions_clustered_xprs (transaction_dt DATE, transaction_id INT, customer_id INT, amount INT)
cluster by ( date_trunc('MONTH', transaction_dt))
as select transaction_dt, transaction_id, customer_id, amount
from transactions_clustered_large;

select count(*) from transactions_clustered_xprs where date_trunc('MONTH', transaction_dt) = date '2018-12-01';

select count(*) from transactions_large where date_trunc('MONTH', transaction_dt) = date '2018-12-01';

select count(*) from transactions_clustered_large where date_trunc('MONTH', transaction_dt) = date '2018-12-01';
 
DROP SCHEMA perf;

DROP DATABASE performance_db;

DROP warehouse performance_test;

--------------------------------------------------
Time travel

alter session set timezone = 'UTC';

create or replace database timetraveldb;

use database timetraveldb;

create or replace schema timetravel;

use schema timetravel;

create table customer 
( name STRING, email STRING, job STRING, phone STRING, age NUMBER);

create or replace file format csv_file_format type = csv field_delimiter='|' skip_header=1;

create or replace stage s3_stage URL='s3://snowflake-essentials/' file_format =  (format_name = csv_file_format);

copy into customer from @s3_stage/sample_data_for_cloned_timetravel.csv ;

select * from customer;

select current_timestamp;
-- z

update customer set job = 'My Job';
--stmtid = abc

select * from customer at(timestamp => z::timestamp);

select * from customer before(timestamp => z+1::timestamp);

select * from customer at(offset => -60*30);

select * from customer before(statement => 'abc');

create table restored_customer clone customer before(timestamp => z+1::timestamp); 

show tables history like '%CUSTOMER%' in TIMETRAVELDB.TIMETRAVEL;
-- assume customer table had been dropped earlier. The above command will show two records for customer, with the dropped_on column for one of the records having the 
-- date when the table was dropped.

alter table customer rename to customer_latest;

undrop table customer;

DROP database timetraveldb;

DROP schema timetravel;

-----------------------------------------------------------------------------
-- Setting up access between S3 and snowflake for external storage

1. Create s3 bucket
2. Configure access permissions for the s3 bucket
        
    s3:GetObject

    s3:GetObjectVersion

    s3:ListBucket

3. create an AWS IAM policy

        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                      "s3:PutObject",
                      "s3:GetObject",
                      "s3:GetObjectVersion",
                      "s3:DeleteObject",
                      "s3:DeleteObjectVersion"
                    ],
                    "Resource": "arn:aws:s3:::<bucket>/<prefix>/*"
                },
                {
                    "Effect": "Allow",
                    "Action": "s3:ListBucket",
                    "Resource": "arn:aws:s3:::<bucket>",
                    "Condition": {
                        "StringLike": {
                            "s3:prefix": [
                                "<prefix>/*"
                            ]
                        }
                    }
                }
            ]
        }

4. Create an IAM role

    <refer to https://docs.snowflake.net/manuals/user-guide/data-load-s3-config.html#step-2-create-the-aws-iam-role>

5. Create a Cloud Storage Integration in Snowflake

    CREATE STORAGE INTEGRATION s3_integration
      TYPE = EXTERNAL_STAGE
      STORAGE_PROVIDER = S3
      ENABLED = TRUE
      STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::<>:role/mysnowflakerole'
      STORAGE_ALLOWED_LOCATIONS = ('s3://snowflake-tryout/data');
     

6. Retrieve STORAGE_AWS_IAM_USER_ARN & STORAGE_AWS_EXTERNAL_ID from the storage integration
    DESC integration s3_integration;

7. Grant the IAM User Permissions to Access Bucket Objects
    Edit the trust relationship in the IAM role created with the STORAGE_AWS_IAM_USER_ARN & STORAGE_AWS_EXTERNAL_ID
    
8. Create an external stage

    CREATE OR REPLACE DATABASE integration_db;
    
    USE DATABASE integration_db;
    
    CREATE OR REPLACE SCHEMA int;
    
    GRANT USAGE ON DATABASE integration_db TO ROLE developer;
    
    GRANT USAGE ON SCHEMA int TO ROLE developer;
    
    GRANT CREATE STAGE on schema int TO ROLE developer;
    
    GRANT CREATE FILE FORMAT ON schema int TO ROLE developer;
    
    GRANT CREATE TABLE ON schema int TO ROLE developer;
    
    GRANT CREATE PROCEDURE ON schema int TO ROLE developer;
    
    GRANT CREATE VIEW ON schema int TO ROLE developer;
    
    GRANT CREATE TASK ON schema int TO ROLE developer;
    
    USE ROLE ACCOUNTADMIN;
    GRANT USAGE ON integration s3_integration TO ROLE developer;
    
    GRANT CREATE PIPE ON schema int TO ROLE developer;
    
    GRANT CREATE STREAM ON schema int TO ROLE developer;  
   
    USE ROLE developer;

------------------------------------------------
-- CREATING pipe

    -- login as dev_1
    
    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;
    
    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE OR REPLACE STAGE s3_stage 
        STORAGE_INTEGRATION = s3_integration 
        URL = 's3://snowflake-tryout/data' 
        file_format=json_file_format;
        
    CREATE TABLE json_raw ( col variant);

    CREATE OR REPLACE PIPE int_pipe auto_ingest = true AS
        COPY INTO json_raw FROM @s3_stage;

            
    ---At this stage, place some file(s) in the S3 bucket and query the SYSTEM$PIPE_STATUS table:

    SELECT SYSTEM$PIPE_STATUS('integration_db.int.int_pipe');

    ---if the status is "", then we are good.
    ---"executionState":"RUNNING"

    ---Query the raw stage table to check the contents of the S3 files loaded.
    SELECT * FROM json_raw;

    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM @s3_stage s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;    

--------------------------------------------------------

--Stream creation

-- standard stream creation 
    CREATE OR REPLACE STREAM contacts_changes_stream ON TABLE contacts_raw; 

    -- Target Table
    CREATE TABLE contacts ( id NUMBER, name STRING, phone STRING, email STRING);   
    
    -- Creating a view using the stream to obtain the changed records.
    -- Will be useful to update / insert into the master table
    CREATE OR REPLACE VIEW contact_raw_view (id, name, phone, email, rec_status) 
    AS
        SELECT a.id, a.name, a.phone, a.email, 'I'    
        FROM contacts_changes_stream a 
        WHERE (a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='False') 
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'D'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'DELETE' and a.METADATA$ISUPDATE='False'
          AND NOT EXISTS ( SELECT '1' FROM contacts_changes_stream b
                           WHERE b.METADATA$ACTION = 'INSERT' and b.METADATA$ISUPDATE='False'
                             AND a.id = b.id)
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'U'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='True';
    
    -- Update the master contacts table
    
    CREATE OR REPLACE PROCEDURE update_contacts ()
    RETURNS VARCHAR
    LANGUAGE javascript
    AS
    $$
        snowflake.execute( { sqlText :
            `MERGE INTO contacts c USING contact_raw_view cv
            ON c.id = cv.id
            WHEN matched AND cv.rec_status = 'U'
            THEN UPDATE
            SET  c.email = cv.email ,
                 c.phone = cv.phone
            WHEN matched AND cv.rec_status = 'D'
            THEN DELETE
            WHEN NOT MATCHED AND cv.rec_status = 'I'
            THEN INSERT
             (c.id, c.name, c.email, c.phone) VALUES
              (cv.id, cv.name, cv.email, cv.phone)`
        });
    $$
    ;

    -- ELT using Streams

    CREATE OR REPLACE PROCEDURE load_and_transform_contacts ()
    RETURNS VARCHAR
    LANGUAGE javascript
    AS
    $$
        snowflake.execute( { sqlText : `call load_contact_stg()` });
        snowflake.execute( { sqlText : `call load_contact_stg()` });
    $$
    ;
    
    -- invoking procedure
    call load_and_transform_contacts();
    
--------------------------

    -- Task Creation
    CREATE OR REPLACE TASK load_and_transform_task WAREHOUSE='compute_wh'
    SCHEDULE= '1 MINUTE'
    AS
        call load_and_transform_contacts();
    


    USE ROLE ACCOUNTADMIN;
    DROP DATABASE integration_db;

-------------------------------------------------------------------
    -- Using Shares across two accounts:

    --Producer Account = <acc1>
    --Consumer Account = <acc2>
    
    -- Please run the create database and schema scripts as mentioned above.

    --Login into the producer account as dev_1
    
    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;

    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE OR REPLACE STAGE s3_stage 
        STORAGE_INTEGRATION = s3_integration 
        URL = 's3://snowflake-tryout/data' 
        file_format=json_file_format;
        
    CREATE TABLE json_raw ( col variant);

    CREATE OR REPLACE PIPE int_pipe auto_ingest = true AS
        COPY INTO json_raw FROM @s3_stage;        
        
    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM @s3_stage s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;
        
        -- Login as sysadmin
        
        USE ROLE accountadmin;

        CREATE OR REPLACE SHARE contacts_share;
        
        GRANT USAGE ON DATABASE integration_db TO SHARE contacts_share;
        
        GRANT USAGE ON SCHEMA integration_db.int TO SHARE contacts_share;
        
        GRANT SELECT ON integration_db.int.contacts_raw TO SHARE contacts_share;
        
        -- Sharing a complete database
        GRANT SELECT ON ALL TABLES IN DATABASE integration_db  TO SHARE contacts_share;

        -- Sharing a complete schema
        GRANT SELECT ON ALL TABLES IN SCHEMA integration_db.int  TO SHARE contacts_share;
        
        SHOW SHARES;
        
        SHOW GRANTS TO SHARE contacts_share;

        ALTER SHARE contacts_share ADD ACCOUNT=<acc2>;
       
       -----------------------------------------------------
       
        --Login into the consumer account
        
        USE ROLE accountadmin;
        
        CREATE OR REPLACE ROLE developer;
        
        GRANT ROLE developer TO USER <user>;
        
        GRANT USAGE ON WAREHOUSE compute_wh TO ROLE developer;
        
        show shares;
        -- should see inbound share
        
        CREATE DATABASE contact_db FROM SHARE <>.CONTACTS_SHARE;
        
        GRANT IMPORTED PRIVILEGES ON DATABASE contact_db TO developer;
        
        USE ROLE developer;
        
        USE DATABASE contact_db;
        
        SELECT * FROM int.contacts_raw;
       ---------------------------------------
       
       -- Login to the producer account
       
        USE ROLE ACCOUNTADMIN;
        
        DROP SHARE CONTACTS_SHARE;
        
        DROP DATABASE integration_db;
        
      -- Login to the consumer account
        USE ROLE ACCOUNTADMIN;
        
        DROP ROLE developer;
        
        DROP DATABASE contact_db; 
-------------------------------------------------------------------        

    --READER ACCOUNTS (non-snowflake user accounts)
    
    -- Login into the producer account and as admin
    
    USE ROLE accountadmin;
    
    -- Managed account cannot be replaced, Cannot use CREATE OR REPLACE 
    CREATE MANAGED ACCOUNT managed_acct
    ADMIN_NAME = tony, ADMIN_PASSWORD = 'ChangeMeNextTime123' TYPE= READER;
    
    SHOW MANAGED ACCOUNTS;    
    
    -- Create a share in the producer account
    
    -- Please run the create database and schema scripts as mentioned above.
    
    --Login into the producer account as dev_1

    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;

    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE OR REPLACE STAGE s3_stage 
        STORAGE_INTEGRATION = s3_integration 
        URL = 's3://snowflake-tryout/data' 
        file_format=json_file_format;
        
    CREATE TABLE json_raw ( col variant);

    CREATE OR REPLACE PIPE int_pipe auto_ingest = true AS
        COPY INTO json_raw FROM @s3_stage;        
        
    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM @s3_stage s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;
        
        -- Login as admininstrator
        
        USE ROLE accountadmin;

        CREATE OR REPLACE SHARE contacts_share;
        
        GRANT USAGE ON DATABASE integration_db TO SHARE contacts_share;
        
        GRANT USAGE ON SCHEMA integration_db.int TO SHARE contacts_share;
        
        GRANT SELECT ON integration_db.int.contacts_raw TO SHARE contacts_share;
        
        SHOW SHARES;
        
        SHOW GRANTS TO SHARE contacts_share;

        ALTER SHARE contacts_share ADD ACCOUNT= <reader account locator from the output of SHOW MANAGED ACCOUNTS>;
        
        -- LOGIN AS THE READER ACCOUNT
        
        /* Task 1: Make sure you're logged in as ACCOUNTADMIN. Don't forget to also set the role for your worksheet context as ACCOUNTADMIN.*/
        use role ACCOUNTADMIN;

        /* Task 2: Create Custom Roles (Optional) */
        CREATE ROLE developer;

        /* Task 3: Create Users */
        CREATE USER john PASSWORD='johnyJohny1234' DEFAULT_ROLE = developer MUST_CHANGE_PASSWORD = true;

        /* Task 4: Create Virtual Warehouses (Optional) */
        CREATE OR REPLACE WAREHOUSE reader_WH WAREHOUSE_SIZE=XSMALL INITIALLY_SUSPENDED = TRUE;

        /* Task 5: Create Resource Monitors (Optional) */
        create or replace resource monitor limiter with credit_quota=5000
           triggers on 75 percent do notify
                    on 100 percent do suspend
                    on 110 percent do suspend_immediate;

        /* Task 6: Create a Database from Each Share Shared with the Account */
        CREATE DATABASE contacts_share_db FROM SHARE <>.contacts_share;

        /* Task 7: Grant Required Virtual Warehouse and Database Privileges to Roles */
        GRANT USAGE ON WAREHOUSE reader_WH TO ROLE developer;
        
        GRANT IMPORTED PRIVILEGES ON DATABASE contacts_share_db to role developer;

        GRANT ROLE developer TO user john;
      
        -- login as john
        
        use WAREHOUSE READER_WH;
        use DATABASE CONTACTS_SHARE_DB;
       
        select * from int.CONTACTS_RAW;
        
       -- Login to the producer account
       
        USE ROLE ACCOUNTADMIN;
        
        DROP SHARE CONTACTS_SHARE;
        
        DROP DATABASE integration_db;
        
      -- Login to the consumer account
        USE ROLE ACCOUNTADMIN;
        
        DROP ROLE developer;
        
        DROP DATABASE contacts_share_db; 

-------------------------------------------------------------------------------------------------------    

    -- SHARING VIEWS
    
    -- Login into the producer account and as admin
    
    -- Please run the create database and schema scripts as mentioned above.
    
    -- login as dev_1
    
    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;
    
    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE OR REPLACE STAGE s3_stage 
        STORAGE_INTEGRATION = s3_integration 
        URL = 's3://snowflake-tryout/data' 
        file_format=json_file_format;
        
    CREATE TABLE json_raw ( col variant);

    CREATE OR REPLACE PIPE int_pipe auto_ingest = true AS
        COPY INTO json_raw FROM @s3_stage;

    ---Query the raw stage table to check the contents of the S3 files loaded.
    SELECT * FROM json_raw;

    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM @s3_stage s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;    
        
        CREATE OR REPLACE SECURE VIEW contacts_view  (id, name, phone, email, rec_status) AS
        SELECT id, name, phone, email , 'I'
        FROM contacts_raw;
        
        GRANT SELECT ON contacts_view TO PUBLIC;

        -- Login as sysadmin
        
        USE ROLE accountadmin;

        CREATE OR REPLACE SHARE contacts_share;
        
        GRANT USAGE ON DATABASE integration_db TO SHARE contacts_share;
        
        GRANT USAGE ON SCHEMA integration_db.int TO SHARE contacts_share;
        
        GRANT SELECT ON VIEW integration_db.int.contacts_view TO SHARE contacts_share;
        
        GRANT REFERENCE_USAGE ON DATABASE integration_db TO SHARE contacts_share;
        
        ALTER SHARE contacts_share ADD ACCOUNT=vga82353;
        
        ---------------------------------------------
        --Login into the consumer account
        
        USE ROLE accountadmin;
        
        CREATE OR REPLACE ROLE developer;
        
        GRANT ROLE developer TO USER <user>;
        
        GRANT USAGE ON WAREHOUSE compute_wh TO ROLE developer;
        
        show shares;
        -- should see inbound share
        
        CREATE OR REPLACE DATABASE contact_db FROM SHARE URA72557.CONTACTS_SHARE;
        
        GRANT IMPORTED PRIVILEGES ON DATABASE contact_db TO developer;
        
        USE ROLE developer;
        
        USE DATABASE contact_db;
        
        SELECT * FROM int.contact_raw_view;
        
      -- Login to the producer account
       
        USE ROLE ACCOUNTADMIN;
        
        DROP SHARE CONTACTS_SHARE;
        
        DROP DATABASE integration_db;  
        
      -- Login to the consumer account
        USE ROLE ACCOUNTADMIN;
        
        DROP ROLE developer;
        
        DROP DATABASE contact_db;      
--------------------------------------------------------------------

    -- ***CANNOT CREATE ANY OBJECTS IN A DATABASE CREATED FROM A SHARE IN THE CONSUMER ACCOUNT;*****

    create table exampl21 (num1 number);
     --- 003001 (42501): SQL access control error:                                       
     --- Insufficient privileges to operate on schema 'INT'


    CREATE SCHEMA NEW_SCHEMA;
     --- 003001 (42501): SQL access control error:                                       
     --- Insufficient privileges to operate on database 'CONTACT_DB'


--------------------------------------------------------------------------------------------------------

--CLONING

-- Intent to create clone of an entire database in an existing account and validate the objects that get cloned

-- Create a role and a user for this exercise

-- Login as sysadmin

    use role accountadmin;

    CREATE ROLE data_science;

    GRANT USAGE ON WAREHOUSE compute_wh to data_science;

    CREATE USER ds_1 PASSWORD = '****' LOGIN_NAME = ds_1 DEFAULT_ROLE = data_science
    DEFAULT_WAREHOUSE = 'compute_wh' MUST_CHANGE_PASSWORD = false;
    
    GRANT ROLE DATA_SCIENCE to user ds_1;

-- Create the objects necessary for the exercise

    CREATE OR REPLACE DATABASE integration_db;
    
    CREATE OR REPLACE SCHEMA int;
    
    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE TABLE json_raw ( col variant);
    
    PUT file:///home/hadoop/snowflake/contacts.json @%json_raw;
    
    copy into JSON_RAW from @%json_raw/contacts.json file_format = json_file_format;
    
    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    -- Loading into the target table
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM json_raw s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;

    -- Create stream
    CREATE OR REPLACE STREAM contacts_changes_stream ON TABLE contacts_raw; 

    -- Target Table
    CREATE TABLE contacts ( id NUMBER, name STRING, phone STRING, email STRING);   
    
    -- Creating a view using the stream to obtain the changed records.
    -- Will be useful to update / insert into the master table
    CREATE OR REPLACE VIEW contact_raw_view (id, name, phone, email, rec_status) 
    AS
        SELECT a.id, a.name, a.phone, a.email, 'I'    
        FROM contacts_changes_stream a 
        WHERE (a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='False') 
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'D'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'DELETE' and a.METADATA$ISUPDATE='False'
          AND NOT EXISTS ( SELECT '1' FROM contacts_changes_stream b
                           WHERE b.METADATA$ACTION = 'INSERT' and b.METADATA$ISUPDATE='False'
                             AND a.id = b.id)
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'U'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='True';
    
    
    CREATE OR REPLACE SECURE VIEW contact_raw_sec_view (id, name, phone, email, rec_status) 
    AS
        SELECT a.id, a.name, a.phone, a.email, 'I'    
        FROM contacts_changes_stream a 
        WHERE (a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='False') 
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'D'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'DELETE' and a.METADATA$ISUPDATE='False'
          AND NOT EXISTS ( SELECT '1' FROM contacts_changes_stream b
                           WHERE b.METADATA$ACTION = 'INSERT' and b.METADATA$ISUPDATE='False'
                             AND a.id = b.id)
        UNION ALL
        SELECT a.id, a.name, a.phone, a.email, 'U'    
        FROM contacts_changes_stream a 
        WHERE a.METADATA$ACTION = 'INSERT' and a.METADATA$ISUPDATE='True';
    
    -- Update the master contacts table
    
    CREATE OR REPLACE PROCEDURE update_contacts ()
    RETURNS VARCHAR
    LANGUAGE javascript
    AS
    $$
        snowflake.execute( { sqlText :
            `MERGE INTO contacts c USING contact_raw_view cv
            ON c.id = cv.id
            WHEN matched AND cv.rec_status = 'U'
            THEN UPDATE
            SET  c.email = cv.email ,
                 c.phone = cv.phone
            WHEN matched AND cv.rec_status = 'D'
            THEN DELETE
            WHEN NOT MATCHED AND cv.rec_status = 'I'
            THEN INSERT
             (c.id, c.name, c.email, c.phone) VALUES
              (cv.id, cv.name, cv.email, cv.phone)`
        });
    $$
    ;

    -- ELT using Streams

    CREATE OR REPLACE PROCEDURE load_and_transform_contacts ()
    RETURNS VARCHAR
    LANGUAGE javascript
    AS
    $$
        snowflake.execute( { sqlText : `call load_contact_stg()` });
        snowflake.execute( { sqlText : `call update_contacts()` });
    $$
    ;
    
    -- invoking procedure
    call load_and_transform_contacts();
    
-- Execute the following steps for enabling the ds_1 user to clone an entire database.

    GRANT CREATE DATABASE ON ACCOUNT TO ROLE data_science;
    GRANT CREATE TABLE ON schema int TO ROLE data_science;
    GRANT USAGE ON DATABASE integration_db TO ROLE data_science;
    GRANT SELECT ON TABLE CONTACTS_RAW TO ROLE data_science;
    GRANT SELECT ON TABLE JSON_RAW TO ROLE data_science;
    GRANT USAGE ON TABLE JSON_RAW TO ROLE data_science;
    
    GRANT ALL ON TABLE JSON_RAW TO ROLE data_science;
    GRANT SELECT ON TABLE STAGE JSON_RAW TO ROLE data_science;
    GRANT SELECT ON TABLE CONTACTS TO ROLE data_science;
    GRANT SELECT ON STREAM contacts_changes_stream TO ROLE data_science;
    GRANT USAGE ON SCHEMA int TO ROLE data_science;    
    GRANT USAGE ON FILE FORMAT JSON_FILE_FORMAT TO ROLE data_science;
    GRANT USAGE ON PROCEDURE update_contacts() TO ROLE data_science;
    GRANT OWNERSHIP ON json_raw TO data_science REVOKE CURRENT GRANTS;    
    GRANT SELECT ON VIEW contact_raw_view TO  ROLE data_science;
    GRANT SELECT ON VIEW contact_raw_sec_view TO  ROLE data_science;

-- Login as secondary user with the data_science role and issue the clone command with create database stmt.

    CREATE OR REPLACE DATABASE cloned_int_db CLONE integration_db;
    
    show grants on schema INT ;
    
    use schema INT;
    
    use WAREHOUSE COMPUTE_WH;
    
    select * from contacts_raw;
    
    select * from contacts;

    DROP database cloned_int_db;

    -- Login as primary user
    
    use role accountadmin;
    
    DROP DATABASE integration_db;

    drop role DATA_SCIENCE;

    drop user ds_1;

--------------------------------------------------------------------------------------------------------

-- Unloading of data example:

    -- login into the primary account

    use role accountadmin;
    
    CREATE ROLE developer;
    
    -- assumes that user dev_1 already exists. If not, create dev_1 user
    GRANT ROLE developer TO user dev_1;
    
    GRANT ROLE developer to role sysadmin;

    use role sysadmin;
    
    CREATE OR REPLACE DATABASE integration_db;
    
    USE DATABASE integration_db;
    
    CREATE OR REPLACE SCHEMA int;
    
    GRANT USAGE ON WAREHOUSE compute_wh TO ROLE developer;
    
    GRANT USAGE ON DATABASE integration_db TO ROLE developer;
    
    GRANT USAGE ON SCHEMA int TO ROLE developer;
    
    GRANT CREATE STAGE on schema int TO ROLE developer;
    
    GRANT CREATE FILE FORMAT ON schema int TO ROLE developer;
    
    GRANT CREATE TABLE ON schema int TO ROLE developer;
    
    GRANT CREATE PROCEDURE ON schema int TO ROLE developer;
    
    GRANT CREATE VIEW ON schema int TO ROLE developer;  
    
<< load data into contacts table>>

    -- login as dev_1
    
    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;
    
    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE TABLE json_raw ( col variant);
    
    PUT file:///home/hadoop/snowflake/contacts.json @~
    
    ls @~;

    copy into JSON_RAW from @~/contacts.json file_format = json_file_format PURGE = TRUE;
    
    ---Query the raw stage table to check the contents of the S3 files loaded.
    SELECT * FROM json_raw;

    -- Create the target table
    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    -- Loading into the target table
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM json_raw s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;
        
        -- execute the procedure
        
        call load_contact_stg();
        
        -- Query the target table contacts_raw
        SELECT * FROM contacts_raw;
        
        -- unloading data from target table into CSV file
        
        -- Create a file format for handling CSV data (pipe separated)
        CREATE OR REPLACE FILE FORMAT csv_file_format 
        TYPE = csv
        FIELD_DELIMITER = '|' 
        RECORD_DELIMITER = '\n' 
        SKIP_HEADER = 1 
        FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' 
        TRIM_SPACE = FALSE 
        ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE 
        ESCAPE = 'NONE' 
        ESCAPE_UNENCLOSED_FIELD = '\134' 
        DATE_FORMAT = 'AUTO' ;
        
        -- Use the user stage and unload the data from contacts_raw        
        COPY INTO @~/contacts.csv FROM ( SELECT id, name, phone, email FROM contacts_raw ) file_format = csv_file_format;
        
        -- list the stage
        ls @~;
        
        -- Get the file from user stage into a local directory
        
        get @~/contacts.csv file:///home/hadoop/snowflake;
        
        -- Login to the primary account
        USE ROLE ACCOUNTADMIN;
        
        DROP ROLE developer;
        
        DROP DATABASE integration_db;        
        
----------------------------------------------------------------------------

---- Example of User Defined Function (UDF)

    -- login into the primary account

    use role accountadmin;
    
    CREATE ROLE developer;
    
    -- assumes that user dev_1 already exists. If not, create dev_1 user
    GRANT ROLE developer TO user dev_1;
    
    GRANT ROLE developer to role sysadmin;

    use role sysadmin;
    
    CREATE OR REPLACE DATABASE integration_db;
    
    USE DATABASE integration_db;
    
    CREATE OR REPLACE SCHEMA int;
    
    GRANT USAGE ON WAREHOUSE compute_wh TO ROLE developer;
    
    GRANT USAGE ON DATABASE integration_db TO ROLE developer;
    
    GRANT USAGE ON SCHEMA int TO ROLE developer;
    
    GRANT CREATE STAGE on schema int TO ROLE developer;
    
    GRANT CREATE FILE FORMAT ON schema int TO ROLE developer;
    
    GRANT CREATE TABLE ON schema int TO ROLE developer;
    
    GRANT CREATE PROCEDURE ON schema int TO ROLE developer;
    
    GRANT CREATE FUNCTION ON schema int TO ROLE developer;
    
    GRANT CREATE VIEW ON schema int TO ROLE developer;  
    
    -- login as dev_1
    
    USE warehouse compute_wh;
    
    USE database integration_db;
    
    USE schema int;
    
    CREATE OR REPLACE FILE FORMAT json_file_format type=json ;
    
    CREATE TABLE json_raw ( col variant);
    
    PUT file:///home/hadoop/snowflake/contacts.json @~;
    
    ls @~;

    copy into JSON_RAW from @~/contacts.json file_format = json_file_format PURGE = TRUE;
    
    ---Query the raw stage table to check the contents of the S3 files loaded.
    SELECT * FROM json_raw;

    -- Create the target table
    CREATE TABLE contacts_raw ( id NUMBER, name STRING, phone STRING, email STRING);
    
    -- Loading into the target table
    CREATE OR REPLACE PROCEDURE load_contact_stg()
        RETURNS VARCHAR
        LANGUAGE javascript
        AS
        $$
        
          snowflake.execute( { sqlText :
            `DELETE FROM contacts_raw`});

            var stmt = snowflake.execute( { sqlText :
            `INSERT INTO contacts_raw (id, name, phone, email)
                    SELECT id, name, phone, email FROM
                    (
                    SELECT s.$1:id::number id, 
                           s.$1:name:last::string||', '||s.$1:name:first::string name, 
                           c.value:type::string type,
                           c.value:content::string content
                        FROM json_raw s, 
                         lateral flatten(input => s.$1, path => 'contact') m,
                         lateral flatten (input => m.value:business) c)
                    PIVOT (max(content) for type IN ('phone','email')) as p(id,name, phone, email)
            `});            
        $$
        ;
        
        -- execute the procedure
        
        call load_contact_stg();
        
        -- Query the target table contacts_raw
        SELECT * FROM contacts_raw;
        
        -- Create a UDF
        
        CREATE OR REPLACE FUNCTION my_filter_function()
        RETURNS TABLE (id int)
        AS
        $$
        SELECT id FROM contacts_raw WHERE id > $id_threshold
        $$
        ;        
        
        CREATE OR REPLACE FUNCTION get_contacts( p_id STRING )
        RETURNS TABLE ( id STRING, name STRING, phone STRING, email STRING)
        LANGUAGE JAVASCRIPT
        AS
        $$
            if (p_id == undefined) {
                SELECT id, name, phone, email from contacts_raw;
            } else
                SELECT id, name, phone, email from contacts_raw where id = p_id;
        $$
        ;
        
      
        SELECT * from table(get_contacts());
        
---------------------------------------------------------------------------------------------------------


